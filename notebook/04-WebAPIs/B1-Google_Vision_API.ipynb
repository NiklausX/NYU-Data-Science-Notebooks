{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo pip3 install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Vision API Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full documentation of the API call is at https://cloud.google.com/vision/docs/reference/rest/v1/images/annotate\n",
    "\n",
    "Below, we show a function that takes as input a URL and asks for three types of annotations (face, web, labels). The function returns a dictionary with the JSON responses that come back from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# See documentation at https://cloud.google.com/vision/docs/reference/rest/v1/images/annotate#Type\n",
    "\n",
    "# We will run the following detections for the image in the passed URL\n",
    "# FACE_DETECTION\tRun face detection.\n",
    "# WEB_DETECTION\tRun web detection.\n",
    "# LABEL_DETECTION\tRun label detection.\n",
    "#\n",
    "def process_image_google(url):\n",
    "    endpoint_google_vision = \"https://vision.googleapis.com/v1/images:annotate\"\n",
    "    params = {\n",
    "        'key': 'AIzaSyDNNGSgk1ZgE7lygOMt5l5vV5Ydc1ZYAOM',\n",
    "    }\n",
    "    headers = { \n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "    gvision_data = {\n",
    "      \"requests\": [\n",
    "        {\n",
    "          \"image\":{\n",
    "            \"source\": {\n",
    "                \"imageUri\" : url\n",
    "            }\n",
    "          },\n",
    "          \"features\": [ { \"type\": \"FACE_DETECTION\" },  \n",
    "                        { \"type\": \"LABEL_DETECTION\" },\n",
    "                        { \"type\": \"WEB_DETECTION\" } ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "\n",
    "    resp = requests.post(\n",
    "        endpoint_google_vision, \n",
    "        data=json.dumps(gvision_data), \n",
    "        headers=headers,\n",
    "        params=params \n",
    "    )\n",
    "    \n",
    "    data = resp.json()\n",
    "    return data['responses'][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just a small routine for downloading a URL with an image\n",
    "# and displaying the image in the notebook\n",
    "def show_image(url):\n",
    "    # Save the URL as a local image, and load it\n",
    "    !curl -s $url -o /tmp/test.jpg\n",
    "    im = np.array(Image.open('/tmp/test.jpg'), dtype=np.uint8)\n",
    "\n",
    "    # Create figure and axes\n",
    "    fig,ax = plt.subplots(1, figsize = (10,10))\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(im)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example URLs\n",
    "\n",
    "Feel free to uncomment the URL that you want to analyze, or add your own URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panos \n",
    "url = 'http://www.stern.nyu.edu/faculty/static/photos/panos.jpg'\n",
    "\n",
    "# Hillary Clinton and Bernie Sanders\n",
    "# url = 'https://lifesite-cache.s3.amazonaws.com/images/made/images/remote/https_s3.amazonaws.com/lifesite/bernie_and_clinton_810_500_75_s_c1.jpg'\n",
    "\n",
    "# Kristaps Porzingis\n",
    "# url = 'https://cdn.newsday.com/polopoly_fs/1.14748908.1509768514!/httpImage/image.jpeg_gen/derivatives/landscape_768/image.jpeg'\n",
    "\n",
    "# Group of students\n",
    "# url = 'https://thumbs.dreamstime.com/z/group-students-happy-classroom-34668743.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the Google API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = process_image_google(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `response` is a relatively complex object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the top-level keys of the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the three result types for the three types of analyses that we requested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Detection Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_detection = response['webDetection']\n",
    "web_detection.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_detection['bestGuessLabels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_detection['webEntities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract just the text for each entity\n",
    "# We keep only entities with score above the score_threshold\n",
    "score_threshold = 0.5\n",
    "entities = web_detection['webEntities']\n",
    "[entity['description'] for entity in entities if entity['score']>score_threshold and 'description' in entity]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels for the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = response['labelAnnotations']\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract just the text for each label\n",
    "# We keep only entries with score above the score_threshold\n",
    "score_threshold = 0.5\n",
    "for entry in labels:\n",
    "    if entry['score']>score_threshold:\n",
    "        print(entry['description'], \"==>\", entry['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract just the text for each label\n",
    "# We keep only entries with score above the score_threshold\n",
    "score_threshold = 0.5\n",
    "[entry['description'] for entry in labels if entry['topicality']>score_threshold]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_annotations = response['faceAnnotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_faces = len(face_annotations)\n",
    "print(\"We identified {num_faces} face(s) in the photo\".format(num_faces=num_faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The face annotations contain a few entries/keys that have a simple string as value\n",
    "# We print these below\n",
    "for face in face_annotations:\n",
    "    for key, value in face.items():\n",
    "        if type(value) == str:\n",
    "            print(key, \"==>\", value)\n",
    "    print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a function that draws a bounding box around each face identified in the image\n",
    "def show_image_with_annotations(url, face_annotations):\n",
    "    ax = show_image(url)\n",
    "    # For every face identified in the photo, draw a bounding box around it\n",
    "    for face in face_annotations:\n",
    "\n",
    "        # Identify the bounding box coordinates for the face\n",
    "        # in the results that were returned by Google\n",
    "        vertices = face['fdBoundingPoly']['vertices']\n",
    "        x_min = min([v['x'] for v in vertices])\n",
    "        x_max = max([v['x'] for v in vertices])\n",
    "        y_min = min([v['y'] for v in vertices])\n",
    "        y_max = max([v['y'] for v in vertices])\n",
    "        height = y_max - y_min\n",
    "        width  = x_max - x_min\n",
    "\n",
    "        # Create a Rectangle box around the face\n",
    "        rect = patches.Rectangle((x_min,y_min),width,height,linewidth=5,edgecolor='green',facecolor='none')\n",
    "        ax.add_patch(rect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_with_annotations(url, face_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
